{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "WiX48SoQgnqQ",
        "6tE2PIJFIepf",
        "T3pMYhsNIBy-",
        "XG_1SzVnIZsj",
        "_s_4pyEVj2g-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adrianav0510/DeltaNews/blob/main/DeltaNews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BIENVENIDO A DELTA NEWS\n",
        "¡una brújula en el laberinto de opiniones y noticias!\n",
        "\n"
      ],
      "metadata": {
        "id": "PiyiL_YFgJ-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREAMBULO\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Primero ejecute estas celdas para el correcto funcionamiento del codigo.\n",
        "\n",
        "Para ejecutar, tan solo haga click en el botón de simbolo \"play\"."
      ],
      "metadata": {
        "id": "WiX48SoQgnqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BIBLIOTECAS PARA LA EJECUCIÓN"
      ],
      "metadata": {
        "id": "6tE2PIJFIepf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#WEB SCRAPING\n",
        "!pip install nltk\n",
        "!pip install newspaper3k\n",
        "\n",
        "#ANALISIS DE SENTIMIENTOS\n",
        "#TRADUCTOR\n",
        "!pip install translate\n",
        "!pip install googletrans==3.1.0a0\n",
        "\n",
        "#ANALISIS DE SENTIMIENTOS\n",
        "!pip install textblob\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from newspaper import Article\n",
        "from googletrans import Translator\n",
        "from textblob import TextBlob\n",
        "\n",
        "#VISUALIZACIONES\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Rq1Zcdu2LXfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FUNCIONES PARA LA EJECUCIÓN"
      ],
      "metadata": {
        "id": "ao_dLlfggClH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#FUNCION PRINCIPAL PARA EL ANALISIS\n",
        "def analizar_noticias_con_input():\n",
        "  \"\"\"\n",
        "  Analiza una lista de URLs de noticias, extrayendo información, limpiando texto,\n",
        "  realizando análisis de sentimiento, categorizando los resultados e\n",
        "  identificando la ciudad más mencionada en cada noticia.\n",
        "  Las URLs son obtenidas del usuario.\n",
        "\n",
        "  Returns:\n",
        "    Un DataFrame de Pandas con los resultados del análisis.\n",
        "  \"\"\"\n",
        "  urls = []\n",
        "  while True:\n",
        "    url = input(\"Ingrese una URL (o escriba 'fin' para terminar): \")\n",
        "    if url.lower() == 'fin':\n",
        "      break\n",
        "    urls.append(url)\n",
        "\n",
        "  #INICIALIZAMOS NUESTROS CONTENEDORES PARA EL DF\n",
        "  text=[]\n",
        "  publisg_date=[]\n",
        "  title=[]\n",
        "  authors=[]\n",
        "  summary = []\n",
        "\n",
        "  #DESCARGAMOS NUESTROS ARTICULOS Y ALMACENAMOS SUS PARTES\n",
        "  for url in urls:\n",
        "    article= Article(url)\n",
        "    article.download()\n",
        "    article.parse()\n",
        "    nltk.download('punkt')\n",
        "    article.nlp()\n",
        "    title.append(article.title)\n",
        "    authors.append(article.authors)\n",
        "    publisg_date.append(article.publish_date)\n",
        "    summary.append(article.summary)\n",
        "    text.append(article.text)\n",
        "\n",
        "  #CREAMOS EL DATAFRAME\n",
        "  dic_df = {\n",
        "      'title': title,\n",
        "      'authors': authors,\n",
        "      'publisg_date': publisg_date,\n",
        "      'summary': summary,\n",
        "      'text': text\n",
        "  }\n",
        "  df = pd.DataFrame(dic_df)\n",
        "\n",
        "  #LIMPIAMOS LOS DATOS, ES NEECESARIO HACERLO EN ESPAÑOL, CONSIDERANDO LOS SIGNOS DE PUNNTUACIÓN\n",
        "  nltk.download('stopwords')\n",
        "  stop_words_es = set(stopwords.words('spanish'))\n",
        "\n",
        "  #NUESTRA FUNCIÓN DE LIMPIEZA\n",
        "  def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-ZáéíóúÁÉÍÓÚñÑüÜ ]+', '', text)\n",
        "    text = text.lower()\n",
        "    words = text.split()\n",
        "    cleaned_words = [word for word in words if word not in stop_words_es]\n",
        "    return ' '.join(cleaned_words)\n",
        "\n",
        "  #APLICAMOS CLEAN_TEXT\n",
        "  df['title_clean'] = df['title'].apply(clean_text)\n",
        "  df['text_clean'] = df['text'].apply(clean_text)\n",
        "\n",
        "  #PAARA ANALIZAR LOS SENTIMIENTOS, ES NECESARIO TRADUCIR AL INGLES\n",
        "  #EN EL FUTURO PODEMOS APLICAR UNA VARIEDAD DE MODELOS DE MACHINE LEARNING PARA LOS FINES ESPECIFICOS DE NUESTRO PROYECTO\n",
        "  #DE TODOS LOS MODELOS DE ML, ELEGIREMOS EL MÁS PRECISO.\n",
        "  translator = Translator()\n",
        "\n",
        "  def analyze_sentiment(text):\n",
        "    translation = translator.translate(text, dest='en')\n",
        "    blob = TextBlob(translation.text)\n",
        "    return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
        "\n",
        "  #APLICAMOS LA FUNCIÓN DE ANALISIS DE SENTIMIENTOS\n",
        "  df['title_sentiment'], df['title_subjectivity'] = zip(*df['title_clean'].apply(analyze_sentiment))\n",
        "  df['text_sentiment'], df['text_subjectivity'] = zip(*df['text_clean'].apply(analyze_sentiment))\n",
        "\n",
        "  #AQUI CATEGORIZAMOS LOS SENTIMIENTOS EN POSITIVO, NEGATIVO O NEUTRAL.\n",
        "  def categorize_sentiment(sentiment_score):\n",
        "    if sentiment_score > 0:\n",
        "      return 'positivo'\n",
        "    elif sentiment_score < 0:\n",
        "      return 'negativo'\n",
        "    else:\n",
        "      return 'neutral'\n",
        "\n",
        "  df['sentiment_category_title'] = df['title_sentiment'].apply(categorize_sentiment)\n",
        "  df['sentiment_category_text'] = df['text_sentiment'].apply(categorize_sentiment)\n",
        "\n",
        "  #POR ULTIMO, CATEGORIZAMOS LA SUBJETIVIDAD.\n",
        "  def categorize_subjectivity(subjectivity_score):\n",
        "    if subjectivity_score >= 0.5:\n",
        "      return 'subjetiva'\n",
        "    else:\n",
        "      return 'objetiva'\n",
        "\n",
        "  df['subjectivity_category_title'] = df['title_subjectivity'].apply(categorize_subjectivity)\n",
        "  df['subjectivity_category_text'] = df['text_subjectivity'].apply(categorize_subjectivity)\n",
        "\n",
        "  #IDENTIFICAR CIUDAD MÁS MENCIONADA\n",
        "  ciudades_principales = [\n",
        "    \"Bogotá\",\n",
        "    \"Medellín\",\n",
        "    \"Cali\",\n",
        "    \"Barranquilla\",\n",
        "    \"Cartagena\",\n",
        "    \"Cúcuta\",\n",
        "    \"Bucaramanga\",\n",
        "    \"Pereira\",\n",
        "    \"Santa Marta\",\n",
        "    \"Ibagué\",\n",
        "    \"Manizales\",\n",
        "    \"Neiva\",\n",
        "    \"Villavicencio\",\n",
        "    \"Pasto\",\n",
        "    \"Armenia\",\n",
        "    \"Valledupar\",\n",
        "    \"Montería\",\n",
        "    \"Popayán\",\n",
        "    \"Sincelejo\",\n",
        "    \"Riohacha\",\n",
        "    \"Tunja\",\n",
        "    \"Florencia\"\n",
        "  ]\n",
        "\n",
        "  def count_city_mentions(text, cities):\n",
        "    city_counts = {}\n",
        "    text_lower = text.lower()\n",
        "    for city in cities:\n",
        "      city_lower = city.lower()\n",
        "      city_counts[city] = text_lower.count(city_lower)\n",
        "    return city_counts\n",
        "\n",
        "  def most_mentioned_city(city_mentions):\n",
        "    if not city_mentions:\n",
        "      return None\n",
        "    most_mentioned = max(city_mentions, key=city_mentions.get)\n",
        "    return most_mentioned\n",
        "\n",
        "  most_mentioned_cities = []\n",
        "  for text in df['text']:\n",
        "    city_counts = count_city_mentions(text, ciudades_principales)\n",
        "    most_mentioned = most_mentioned_city(city_counts)\n",
        "    most_mentioned_cities.append(most_mentioned)\n",
        "\n",
        "  df['ciudad_mas_mencionada'] = most_mentioned_cities\n",
        "\n",
        "  return df\n",
        "\n"
      ],
      "metadata": {
        "id": "5AW5QZpPZWGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_graficos_torta(df):\n",
        "  \"\"\"\n",
        "  Genera cuatro gráficos de torta que muestran la distribución de la subjetividad\n",
        "  y los sentimientos tanto en los títulos como en el texto de las noticias.\n",
        "\n",
        "  Args:\n",
        "    df: Un DataFrame de Pandas con los resultados del análisis de noticias.\n",
        "\n",
        "  Returns:\n",
        "    None. Muestra los gráficos directamente.\n",
        "  \"\"\"\n",
        "  #GRACIAS HACKATHON POR HACERME CONOCER ESTE ESTILO PRECIOSO\n",
        "  plt.style.use('https://github.com/dhaitz/matplotlib-stylesheets/raw/master/pitayasmoothie-dark.mplstyle')\n",
        "\n",
        "  #TITULOS\n",
        "  #SUBJETIVIDAD:\n",
        "  category_counts_sub_title = df.groupby(['subjectivity_category_title'])['subjectivity_category_title'].count()\n",
        "  counts_sub_title = pd.DataFrame(category_counts_sub_title).rename(columns={\"subjectivity_category_title\": \"Counts\"})\n",
        "\n",
        "  #SENTIMIENTO:\n",
        "  category_counts_sent_title = df.groupby(['sentiment_category_title'])['sentiment_category_title'].count()\n",
        "  counts_sent_title = pd.DataFrame(category_counts_sent_title).rename(columns={\"sentiment_category_title\": \"Counts\"})\n",
        "\n",
        "  #TEXTO - NOTICIA\n",
        "  #SUBJETIVIDAD:\n",
        "  category_counts_sub_text = df.groupby(['subjectivity_category_text'])['subjectivity_category_text'].count()\n",
        "  counts_sub_text = pd.DataFrame(category_counts_sub_text).rename(columns={\"subjectivity_category_text\": \"Counts\"})\n",
        "\n",
        "  #SENTIMIENTO:\n",
        "  category_counts_sent_text = df.groupby(['sentiment_category_text'])['sentiment_category_text'].count()\n",
        "  counts_sent_text = pd.DataFrame(category_counts_sent_text).rename(columns={\"sentiment_category_text\": \"Counts\"})\n",
        "\n",
        "  #CREAR LOS SUBPLOTS\n",
        "  fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
        "\n",
        "  #GRAFICO 1 - SUBJETIVIDAD DE LOS TITULOS\n",
        "  axes[0, 0].pie(counts_sub_title['Counts'], labels=counts_sub_title.index, autopct='%1.1f%%', startangle=90)\n",
        "  axes[0, 0].axis('equal')\n",
        "  axes[0, 0].set_title('Subjetividad de Títulos')\n",
        "\n",
        "  #GRAFICO 2 - SENTIMIENTO DE LOS TITULOS\n",
        "  axes[0, 1].pie(counts_sent_title['Counts'], labels=counts_sent_title.index, autopct='%1.1f%%', startangle=90)\n",
        "  axes[0, 1].axis('equal')\n",
        "  axes[0, 1].set_title('Sentimiento de Títulos')\n",
        "\n",
        "  #GRAFICO 3 - SUBJETIVIDAD DEL TEXTO - NOTICIA\n",
        "  axes[1, 0].pie(counts_sub_text['Counts'], labels=counts_sub_text.index, autopct='%1.1f%%', startangle=90)\n",
        "  axes[1, 0].axis('equal')\n",
        "  axes[1, 0].set_title('Subjetividad de Texto')\n",
        "\n",
        "  #GRAFICO 4 - SENTIMIENTO DEL TEXTO NOTICIA\n",
        "  axes[1, 1].pie(counts_sent_text['Counts'], labels=counts_sent_text.index, autopct='%1.1f%%', startangle=90)\n",
        "  axes[1, 1].axis('equal')\n",
        "  axes[1, 1].set_title('Sentimiento de Texto')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "uceLpSsPIBiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_mapa_calor_correlacion(df):\n",
        "  \"\"\"\n",
        "  Genera un mapa de calor que muestra la correlación entre las variables\n",
        "  de sentimiento y subjetividad en los títulos y el texto de las noticias.\n",
        "\n",
        "  Args:\n",
        "    df: Un DataFrame de Pandas con los resultados del análisis de noticias.\n",
        "\n",
        "  Returns:\n",
        "    Un objeto matplotlib.axes.Axes que representa el mapa de calor.\n",
        "  \"\"\"\n",
        "\n",
        "  # PARA EL HEATMAP, ES NECESARIO LA MATRIZ DE CORRELACIÓN\n",
        "  correlation_matrix = df[['title_sentiment', 'title_subjectivity', 'text_sentiment', \"text_subjectivity\"]].corr()\n",
        "\n",
        "  #CREAMOS EL HEATMAP\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  ax = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
        "  plt.title('Correlation Heatmap')\n",
        "  return ax"
      ],
      "metadata": {
        "id": "V6a5pfLCVpnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_nubes_palabras(df):\n",
        "  \"\"\"\n",
        "  Genera dos nubes de palabras, una para los títulos y otra para el texto de las noticias.\n",
        "\n",
        "  Args:\n",
        "    df: Un DataFrame de Pandas con los resultados del análisis de noticias.\n",
        "\n",
        "  Returns:\n",
        "    Una tupla de dos objetos WordCloud, el primero para los títulos y el segundo para el texto.\n",
        "  \"\"\"\n",
        "  #NO BORRAR\n",
        "  nltk.download('stopwords')\n",
        "  stop_words_es = set(stopwords.words('spanish'))\n",
        "\n",
        "  #WORDCLOUD PARA TITULARES\n",
        "  text_titulos = \" \".join(title for title in df.title_clean)\n",
        "  wordcloud_titulos = WordCloud(width=800, height=800,\n",
        "                                background_color='black',\n",
        "                                stopwords=stop_words_es,\n",
        "                                min_font_size=10).generate(text_titulos)\n",
        "\n",
        "  #WORLDCLOUD PARA LAS NOTICIAS\n",
        "  text_texto = \" \".join(texto for texto in df.text_clean)\n",
        "  wordcloud_texto = WordCloud(width=800, height=800,\n",
        "                               background_color='black',\n",
        "                               stopwords=stop_words_es,\n",
        "                               min_font_size=10).generate(text_texto)\n",
        "\n",
        "  return wordcloud_titulos, wordcloud_texto\n"
      ],
      "metadata": {
        "id": "3Ki9gIcdWLCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WEB SCRAPPING Y ANALISIS DE LA NOTICIA\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Visualice y ejecute la celda, despues introduzca los links de las noticias.\n",
        "\n",
        "Mientras más noticias ingrese, mejores y más confiables seran las visualizaciones.\n"
      ],
      "metadata": {
        "id": "T3pMYhsNIBy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_resultados = analizar_noticias_con_input()\n",
        "\n",
        "for index, row in df_resultados.iterrows():\n",
        "  print(f\"Titular: {row['title']}\")\n",
        "  print(f\"Sentimiento del titular: {row['sentiment_category_title']}\")\n",
        "  print(f\"Subjetividad del titular: {row['subjectivity_category_title']}\")\n",
        "  print(f\"Sentimiento de la noticia: {row['sentiment_category_text']}\")\n",
        "  print(f\"Subjetividad de la noticia: {row['subjectivity_category_text']}\")\n",
        "  print(f\"Ciudad de la noticia: {row['ciudad_mas_mencionada']}\")\n",
        "  print(\"-\" * 30)\n"
      ],
      "metadata": {
        "id": "SBDS8dQneA_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VISUALIZACIONES\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Una imagen vale más que mil palabras.\n",
        "\n",
        "Observe el analisis gracias a las funciones de visualización"
      ],
      "metadata": {
        "id": "XG_1SzVnIZsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La siguiente celda crea un gráfico de torta a partir de las noticias analizadas:"
      ],
      "metadata": {
        "id": "XsbvfueTi-01"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04zd_lVoIAf4",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#GRAFICO DE TORTA\n",
        "generar_graficos_torta(df_resultados)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La siguiente celda crea un heatmap - grafico de calor - que permite visualizar la relacion del analisis de la noticia:"
      ],
      "metadata": {
        "id": "f9a7VTfTjGgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#HEATMAP - Grafico de Calor\n",
        "ax = generar_mapa_calor_correlacion(df_resultados)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ywct0w0tVwhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La siguiente celda crea un WordCloud - nube de palabras - que permite visualizar la narrativa del conjunto de noticias:"
      ],
      "metadata": {
        "id": "QK5TKDgujn3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#EJEMPLO DE USO - NO BORRAR\n",
        "wordcloud_titulos, wordcloud_texto = generar_nubes_palabras(df_resultados)\n",
        "\n",
        "#ESTO ES NECESARIO PARA MOSTRAR AMBOS A LA VEZ.\n",
        "plt.figure(figsize=(8, 8), facecolor=None)\n",
        "plt.imshow(wordcloud_titulos)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad=0)\n",
        "plt.title(\"Nube de Palabras - Títulos\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 8), facecolor=None)\n",
        "plt.imshow(wordcloud_texto)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad=0)\n",
        "plt.title(\"Nube de Palabras - Texto\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IWdEUOEzWVQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataframe con los datos"
      ],
      "metadata": {
        "id": "_s_4pyEVj2g-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la siguiente linea puede visualizar el df producto del analisis."
      ],
      "metadata": {
        "id": "-8MfIVytj_1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_resultados"
      ],
      "metadata": {
        "id": "pSBXO2VZkF7g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}